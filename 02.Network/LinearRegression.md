# 线性回归

回归：寻找输入变量与输出变量间的对应关系，常通过类似于对已有数据集进行拟合的方法进行。但考虑到模型稳定性和泛化性，并非对训练数据集拟合误差越小越好，需要加入正则化过程。

应用：股市预测、自动驾驶、商品推荐。

## 学习步骤

### 模型假设

#### 线性模型

$$ Y = WX + B $$

Y为输出向量，X为输入向量，W与B为线性映射参数。学习过程即是寻找最优参数，使得输入经此映射后尽可能接近输出。

线性模型的特点：

+ 模型简单，计算方便，可以根据系数给出每个变量的理解和解释。
+ 即使复杂的映射在局部也可以很好地近似为线性映射。所以，线性模型的适用范围较广。也因此，线性模型主要适用于输入输出间的映射相对“光滑”的情况，即当输入变化不大时，输出变化也不大。

拟合效果时不好常见改进方案：

+ 存在对输入影响较大的特征输入未被考虑。可通过添加输入特征优化。
+ 映射的线性程度不高。可通过对原先特征进行非线性化处理，例如添加lnX、X^n、e^X等方式优化。

### 模型评估

设定对模型反应映射关系能力的判据。
损失函数用来评价模型的预测值与真实值的不一致程度，它是一个非负实值函数。常见型式：

+ 误差绝对值均值，$ L(f)=\frac{1}{N}\sum |e| $
+ 误差平方均值，$ L(f)=\frac{1}{N}\sum e^2 $

### 模型最优化

使模型参数达到最优，损失函数最小。

#### 梯度下降

由于给出的训练数据集固定，损失函数只与模型参数有关。


